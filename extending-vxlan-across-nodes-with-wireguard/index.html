<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Extending a VXLAN across nodes with Wireguard | Linuxera</title><meta name=keywords content="wireguard,networking,vxlan"><meta name=description content="Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don&rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.
Getting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time."><meta name=author content="Mario"><link rel=canonical href=https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/><link crossorigin=anonymous href=/assets/css/stylesheet.8cc7ef3cdd44c5188f9267864f378d8dd8892d583e0fd07b5e5321e496f1e4d1.css integrity="sha256-jMfvPN1ExRiPkmeGTzeNjdiJLVg+D9B7XlMh5Jbx5NE=" rel="preload stylesheet" as=style><link rel=icon href=https://linuxera.org/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://linuxera.org/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://linuxera.org/favicon-32x32.png><link rel=apple-touch-icon href=https://linuxera.org/apple-touch-icon.png><link rel=mask-icon href=https://linuxera.org/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-7598JKCK1E"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7598JKCK1E",{anonymize_ip:!1})}</script><meta property="og:title" content="Extending a VXLAN across nodes with Wireguard"><meta property="og:description" content="Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don&rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.
Getting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time."><meta property="og:type" content="article"><meta property="og:url" content="https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-12-19T00:00:00+00:00"><meta property="article:modified_time" content="2023-12-19T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Extending a VXLAN across nodes with Wireguard"><meta name=twitter:description content="Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don&rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.
Getting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://linuxera.org/posts/"},{"@type":"ListItem","position":2,"name":"Extending a VXLAN across nodes with Wireguard","item":"https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Extending a VXLAN across nodes with Wireguard","name":"Extending a VXLAN across nodes with Wireguard","description":"Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don\u0026rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.\nGetting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time.","keywords":["wireguard","networking","vxlan"],"articleBody":"Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don‚Äôt always need these environments to talk to each other, from time to time I need some sort of connectivity between them.\nGetting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time. For the last few days, I have been thinking of extending a virtual network across two hypervisors. This allows me to run VMs on this virtual network and get VMs to talk to each other without having to run these VMs in a routed lab network.\nFor this solution to work, we will be using Wireguard to create a tunnel between the two hypervisors using a routed lab network and VXLAN to encapsulate our virtual network in the Wireguard tunnel.\nThe instructions in this blog were tested on RHEL 9. This focuses on IPv4 VXLAN network, but the same should be doable with IPv6.\nWarning\nI‚Äôm far (like really far) from being a Networking expert, take the information in this post with a grain of salt since it may not be 100% accurate (but it works though).\nSolution Overview In the diagram above we can see we have two hypervisors which are connected to a routed lab network via their eth0 interface. We will configure a Wireguard tunnel using this interface, the Wireguard interface will be named wg0. On top of that, we will configure a VXLAN interface that we will connect to the bridge named br0 which will be configured to send traffic via the wg0 tunnel.\nBoth hypervisors will follow this setup. When we create a VM on these hypervisors, we will connect the VM‚Äôs eth0 interface to the bridge br0 and that will place the VM in the VXLAN network. If everything goes according to the plan, we will be able to connect from VM1 in Hypervisor 1 to VM1 in Hypervisor 2 and vice versa.\nInstalling Wireguard Attention\nSteps below must be done on every hypervisor node.\nInstall epel-release repository by following the instructions here.\nInstall elrepo repository by following the instructions here.\nInstall the required packages:\nsudo dnf install -y kmod-wireguard wireguard-tools bridge-utils Make sure the wireguard kernel module is loaded (if you get an error when trying to load the module, you may need to reboot into a newer kernel):\nsudo modprobe wireguard Attention\nIf you get the following error when trying to load the module: modprobe: ERROR: could not insert 'wireguard': Required key not available.\nThis means that you are trying to use ELRepo‚Äôs kernel modules (kmod packages) on a system with Secure Boot enabled, therefore this must import the ELRepo Secure Boot public key into their Machine Owner Key (MOK) list.\nsudo curl -L https://elrepo.org/SECURE-BOOT-KEY-elrepo.org.der -o /etc/pki/elrepo/SECURE-BOOT-KEY-elrepo.org.der Install the downloaded key:\nsudo mokutil --import /etc/pki/elrepo/SECURE-BOOT-KEY-elrepo.org.der When prompted, enter a password of your choice. This password will be used when enrolling the key into the MOK list. Reboot the system and follow-up the BMC interface for entrolling the MOK key. Once the boot finished:\nsudo modprobe wireguard sudo lsmod | grep wireguard wireguard 212992 0 ip6_udp_tunnel 16384 1 wireguard udp_tunnel 20480 1 wireguard Configuring Wireguard Tunnel (wg0) First we need to enable IPv4 forwarding in both hypervisors.\ncat \u003c","wordCount":"2321","inLanguage":"en","datePublished":"2023-12-19T00:00:00Z","dateModified":"2023-12-19T00:00:00Z","author":{"@type":"Person","name":"Mario"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/"},"publisher":{"@type":"Organization","name":"Linuxera","logo":{"@type":"ImageObject","url":"https://linuxera.org/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://linuxera.org/ accesskey=h title="Linuxera (Alt + H)">Linuxera</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://linuxera.org/ title="üè† Home"><span>üè† Home</span></a></li><li><a href=https://linuxera.org/archives/ title="üóÑÔ∏è Archive"><span>üóÑÔ∏è Archive</span></a></li><li><a href=https://linuxera.org/search/ title="üîé Search"><span>üîé Search</span></a></li><li><a href=https://linuxera.org/tags/ title="üè∑Ô∏è Tags"><span>üè∑Ô∏è Tags</span></a></li><li><a href=https://linuxera.org/presentations/ title="üé¥ Presentations"><span>üé¥ Presentations</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://linuxera.org/>Home</a>&nbsp;¬ª&nbsp;<a href=https://linuxera.org/posts/>Posts</a></div><h1 class=post-title>Extending a VXLAN across nodes with Wireguard</h1><div class=post-meta><span title='2023-12-19 00:00:00 +0000 UTC'>Published on December 19, 2023</span>&nbsp;¬∑&nbsp;<span title='2023-12-19 00:00:00 +0000 UTC'>Last updated on December 19, 2023</span>&nbsp;¬∑&nbsp;11 min&nbsp;¬∑&nbsp;Mario</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#extending-a-vxlan-across-nodes-with-wireguard aria-label="Extending a VXLAN across nodes with Wireguard">Extending a VXLAN across nodes with Wireguard</a><ul><li><a href=#solution-overview aria-label="Solution Overview">Solution Overview</a></li><li><a href=#installing-wireguard aria-label="Installing Wireguard">Installing Wireguard</a></li><li><a href=#configuring-wireguard-tunnel-wg0 aria-label="Configuring Wireguard Tunnel (wg0)">Configuring Wireguard Tunnel (wg0)</a><ul><li><a href=#configuring-wireguard-in-hypervisor-1 aria-label="Configuring Wireguard in Hypervisor 1">Configuring Wireguard in Hypervisor 1</a></li><li><a href=#configuring-wireguard-in-hypervisor-2 aria-label="Configuring Wireguard in Hypervisor 2">Configuring Wireguard in Hypervisor 2</a></li></ul></li><li><a href=#starting-and-verifying-wireguard-tunnel aria-label="Starting and verifying Wireguard Tunnel">Starting and verifying Wireguard Tunnel</a></li><li><a href=#configuring-vxlan-br0 aria-label="Configuring VXLAN (br0)">Configuring VXLAN (br0)</a><ul><li><a href=#configuring-vxlan-in-hypervisor-1 aria-label="Configuring VXLAN in Hypervisor 1">Configuring VXLAN in Hypervisor 1</a></li><li><a href=#configuring-vxlan-in-hypervisor-2 aria-label="Configuring VXLAN in Hypervisor 2">Configuring VXLAN in Hypervisor 2</a></li></ul></li><li><a href=#verifying-vxlan-configuration aria-label="Verifying VXLAN configuration">Verifying VXLAN configuration</a></li><li><a href=#configuring-vms-on-vxlan-network aria-label="Configuring VMs on VXLAN network">Configuring VMs on VXLAN network</a></li><li><a href=#cleaning-up-the-environment aria-label="Cleaning up the environment">Cleaning up the environment</a></li><li><a href=#alternative-commands-to-nmcli aria-label="Alternative commands to nmcli">Alternative commands to nmcli</a></li><li><a href=#references aria-label=References>References</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=extending-a-vxlan-across-nodes-with-wireguard>Extending a VXLAN across nodes with Wireguard<a hidden class=anchor aria-hidden=true href=#extending-a-vxlan-across-nodes-with-wireguard>#</a></h1><p>Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don&rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.</p><p>Getting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time. For the last few days, I have been thinking of extending a virtual network across two hypervisors. This allows me to run VMs on this virtual network and get VMs to talk to each other without having to run these VMs in a routed lab network.</p><p>For this solution to work, we will be using Wireguard to create a tunnel between the two hypervisors using a routed lab network and VXLAN to encapsulate our virtual network in the Wireguard tunnel.</p><p>The instructions in this blog were tested on RHEL 9. This focuses on IPv4 VXLAN network, but the same should be doable with IPv6.</p><div class="admonition warning"><p class=admonition-title>Warning</p><p class=admonition>I&rsquo;m far (like really far) from being a Networking expert, take the information in this post with a grain of salt since it may not be 100% accurate (but it works though).</p></div><h2 id=solution-overview>Solution Overview<a hidden class=anchor aria-hidden=true href=#solution-overview>#</a></h2><p><img loading=lazy src=./vxlan-over-wireguard.png alt="VXLAN over Wireguard"></p><p>In the diagram above we can see we have two hypervisors which are connected to a routed lab network via their <code>eth0</code> interface. We will configure a Wireguard tunnel using this interface, the Wireguard interface will be named <code>wg0</code>. On top of that, we will configure a VXLAN interface that we will connect to the bridge named <code>br0</code> which will be configured to send traffic via the <code>wg0</code> tunnel.</p><p>Both hypervisors will follow this setup. When we create a VM on these hypervisors, we will connect the VM&rsquo;s eth0 interface to the bridge <code>br0</code> and that will place the VM in the VXLAN network. If everything goes according to the plan, we will be able to connect from VM1 in Hypervisor 1 to VM1 in Hypervisor 2 and vice versa.</p><h2 id=installing-wireguard>Installing Wireguard<a hidden class=anchor aria-hidden=true href=#installing-wireguard>#</a></h2><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>Steps below must be done on every hypervisor node.</p></div><ol><li><p>Install <code>epel-release</code> repository by following the instructions <a href=https://docs.fedoraproject.org/en-US/epel/>here</a>.</p></li><li><p>Install <code>elrepo</code> repository by following the instructions <a href=https://elrepo.org/tiki/HomePage>here</a>.</p></li><li><p>Install the required packages:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo dnf install -y kmod-wireguard wireguard-tools bridge-utils
</span></span></code></pre></div></li><li><p>Make sure the <code>wireguard</code> kernel module is loaded (if you get an error when trying to load the module, you may need to reboot into a newer kernel):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo modprobe wireguard
</span></span></code></pre></div><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>If you get the following error when trying to load the module: <code>modprobe: ERROR: could not insert 'wireguard': Required key not available</code>.</p></div><p>This means that you are trying to use ELRepo&rsquo;s kernel modules (kmod packages) on a system with Secure Boot enabled, therefore this must import the ELRepo Secure Boot public key into their Machine Owner Key (MOK) list.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo curl -L https://elrepo.org/SECURE-BOOT-KEY-elrepo.org.der -o /etc/pki/elrepo/SECURE-BOOT-KEY-elrepo.org.der
</span></span></code></pre></div><p>Install the downloaded key:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo mokutil --import /etc/pki/elrepo/SECURE-BOOT-KEY-elrepo.org.der
</span></span></code></pre></div><p>When prompted, enter a password of your choice. This password will be used when enrolling the key into the MOK list.
Reboot the system and follow-up the BMC interface for entrolling the MOK key.
Once the boot finished:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo modprobe wireguard
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo lsmod <span class=p>|</span> grep wireguard
</span></span><span class=line><span class=cl>wireguard             <span class=m>212992</span>  <span class=m>0</span>
</span></span><span class=line><span class=cl>ip6_udp_tunnel         <span class=m>16384</span>  <span class=m>1</span> wireguard
</span></span><span class=line><span class=cl>udp_tunnel             <span class=m>20480</span>  <span class=m>1</span> wireguard
</span></span></code></pre></div></li></ol><h2 id=configuring-wireguard-tunnel-wg0>Configuring Wireguard Tunnel (wg0)<a hidden class=anchor aria-hidden=true href=#configuring-wireguard-tunnel-wg0>#</a></h2><ol><li><p>First we need to enable IPv4 forwarding in both hypervisors.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/sysctl.d/wireguard.conf
</span></span></span><span class=line><span class=cl><span class=s>net.ipv4.ip_forward=1
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>sudo sysctl -p /etc/sysctl.d/wireguard.conf
</span></span></code></pre></div></li><li><p>Generate Wireguard keys in both hypervisors.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo mkdir -p /etc/wireguard/certs/
</span></span><span class=line><span class=cl>sudo wg genkey &gt; /etc/wireguard/certs/private_key
</span></span><span class=line><span class=cl>sudo wg pubkey &lt; /etc/wireguard/certs/private_key &gt; /etc/wireguard/certs/public_key
</span></span><span class=line><span class=cl>sudo chmod <span class=m>600</span> /etc/wireguard/certs/private_key
</span></span><span class=line><span class=cl>sudo chmod <span class=m>644</span> /etc/wireguard/certs/public_key
</span></span></code></pre></div></li></ol><h3 id=configuring-wireguard-in-hypervisor-1>Configuring Wireguard in Hypervisor 1<a hidden class=anchor aria-hidden=true href=#configuring-wireguard-in-hypervisor-1>#</a></h3><ul><li>Hypervisor 1 has its <code>eth0</code> interface connected to the lab network and configured with the <code>10.19.3.4/26</code> IP. Hypervisor 1 can reach Hypervisor 2 at <code>10.19.3.5/26</code>.</li><li>Hypervisor 1 will configure <code>172.16.0.1/16</code> IP for <code>wg0</code> and will NAT traffic through its <code>eth0</code> which is connected to the routed lab network.</li><li>Hypervisor 1 Priv Key in this example is: <code>QP1LNvlaejugxgHj+DtDOX20DvBilOCn1RPRBQFakFs=</code></li><li>Hypervisor 1 Pub Key in this example is: <code>3TxNmlyWmNeL4EavtHi9dRfsqPHcEeiexKzMDF7n7nU=</code></li><li>Hypervisor 2 Priv Key in this example is: <code>sIWrsVAvFm/VIHQhHRPaCzBOTWK/jmM6NkGYEwd/oXk=</code></li><li>Hypervisor 2 Pub Key in this example is: <code>GmG2HkjvV8OebDy9ezHPG/+ODb6CMv51oSEKz4StdHQ=</code></li></ul><ol><li><p>Configure <code>wg0</code>:</p><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>Make sure you change the <code>PrivateKey</code> and <code>PublicKey</code> to match the specifics for your environment.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>HYPERVISOR_EXT_NIC</span><span class=o>=</span>eth0
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/wireguard/wg0.conf
</span></span></span><span class=line><span class=cl><span class=s>[Interface]
</span></span></span><span class=line><span class=cl><span class=s>PrivateKey = QP1LNvlaejugxgHj+DtDOX20DvBilOCn1RPRBQFakFs=
</span></span></span><span class=line><span class=cl><span class=s>Address = 172.16.0.1/16
</span></span></span><span class=line><span class=cl><span class=s>ListenPort = 51820
</span></span></span><span class=line><span class=cl><span class=s>PostUp   = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o ${HYPERVISOR_EXT_NIC} -j MASQUERADE
</span></span></span><span class=line><span class=cl><span class=s>PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o ${HYPERVISOR_EXT_NIC} -j MASQUERADE
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[Peer]
</span></span></span><span class=line><span class=cl><span class=s>PublicKey = GmG2HkjvV8OebDy9ezHPG/+ODb6CMv51oSEKz4StdHQ=
</span></span></span><span class=line><span class=cl><span class=s>Endpoint = 10.19.3.5:51820
</span></span></span><span class=line><span class=cl><span class=s>AllowedIPs = 172.16.0.0/16
</span></span></span><span class=line><span class=cl><span class=s>PersistentKeepalive = 25
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></div></li></ol><h3 id=configuring-wireguard-in-hypervisor-2>Configuring Wireguard in Hypervisor 2<a hidden class=anchor aria-hidden=true href=#configuring-wireguard-in-hypervisor-2>#</a></h3><ul><li>Hypervisor 2 has its <code>eth0</code> interface connected to the lab network and configured with the <code>10.19.3.5/26</code> IP. Hypervisor 1 can reach Hypervisor 1 at <code>10.19.3.4/26</code>.</li><li>Hypervisor 2 will configure <code>172.16.0.2/16</code> IP for <code>wg0</code> and will NAT traffic through its <code>eth0</code> which is connected to the routed lab network.</li><li>Hypervisor 1 Priv Key in this example is: <code>QP1LNvlaejugxgHj+DtDOX20DvBilOCn1RPRBQFakFs=</code></li><li>Hypervisor 1 Pub Key in this example is: <code>3TxNmlyWmNeL4EavtHi9dRfsqPHcEeiexKzMDF7n7nU=</code></li><li>Hypervisor 2 Priv Key in this example is: <code>sIWrsVAvFm/VIHQhHRPaCzBOTWK/jmM6NkGYEwd/oXk=</code></li><li>Hypervisor 2 Pub Key in this example is: <code>GmG2HkjvV8OebDy9ezHPG/+ODb6CMv51oSEKz4StdHQ=</code></li></ul><ol><li><p>Configure <code>wg0</code>:</p><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>Make sure you change the <code>PrivateKey</code> and <code>PublicKey</code> to match the specifics for your environment.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nv>HYPERVISOR_EXT_NIC</span><span class=o>=</span>eth0
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF | sudo tee /etc/wireguard/wg0.conf
</span></span></span><span class=line><span class=cl><span class=s>[Interface]
</span></span></span><span class=line><span class=cl><span class=s>PrivateKey = sIWrsVAvFm/VIHQhHRPaCzBOTWK/jmM6NkGYEwd/oXk=
</span></span></span><span class=line><span class=cl><span class=s>Address = 172.16.0.2/16
</span></span></span><span class=line><span class=cl><span class=s>ListenPort = 51820
</span></span></span><span class=line><span class=cl><span class=s>PostUp   = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o ${HYPERVISOR_EXT_NIC} -j MASQUERADE
</span></span></span><span class=line><span class=cl><span class=s>PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o ${HYPERVISOR_EXT_NIC} -j MASQUERADE
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>[Peer]
</span></span></span><span class=line><span class=cl><span class=s>PublicKey = 3TxNmlyWmNeL4EavtHi9dRfsqPHcEeiexKzMDF7n7nU=
</span></span></span><span class=line><span class=cl><span class=s>Endpoint = 10.19.3.4:51820
</span></span></span><span class=line><span class=cl><span class=s>AllowedIPs = 172.16.0.0/16
</span></span></span><span class=line><span class=cl><span class=s>PersistentKeepalive = 25
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></div></li></ol><h2 id=starting-and-verifying-wireguard-tunnel>Starting and verifying Wireguard Tunnel<a hidden class=anchor aria-hidden=true href=#starting-and-verifying-wireguard-tunnel>#</a></h2><p>In both hypervisors run the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo systemctl <span class=nb>enable</span> wg-quick@wg0.service --now
</span></span></code></pre></div><p>If everything went well, Hypervisors should be able to reach each other over the 172.16.0.0/16 network.</p><ol><li><p>We can check <code>wg0</code> state in Hypervisor 1:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wg show wg0
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>interface: wg0
  public key: 3TxNmlyWmNeL4EavtHi9dRfsqPHcEeiexKzMDF7n7nU=
  private key: (hidden)
  listening port: 51820

peer: GmG2HkjvV8OebDy9ezHPG/+ODb6CMv51oSEKz4StdHQ=
  endpoint: 10.19.3.5:51820
  allowed ips: 172.16.0.0/16
  latest handshake: 1 minute, 15 seconds ago
  transfer: 1.56 MiB received, 105.65 MiB sent
</code></pre></li><li><p>Same in Hypervisor 2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wg show wg0
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>interface: wg0
  public key: GmG2HkjvV8OebDy9ezHPG/+ODb6CMv51oSEKz4StdHQ=
  private key: (hidden)
  listening port: 51820

peer: 3TxNmlyWmNeL4EavtHi9dRfsqPHcEeiexKzMDF7n7nU=
  endpoint: 10.19.3.4:51820
  allowed ips: 172.16.0.0/16
  latest handshake: 1 minute, 21 seconds ago
  transfer: 105.76 MiB received, 1.82 MiB sent
</code></pre></li><li><p>Hypervisor 1 pings Hypervisor 2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ping -I wg0 -c <span class=m>1</span> 172.16.0.2
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>PING 172.16.0.2 (172.16.0.2) from 172.16.0.1 wg0: 56(84) bytes of data.
64 bytes from 172.16.0.2: icmp_seq=1 ttl=64 time=0.523 ms

--- 172.16.0.2 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.523/0.523/0.523/0.000 ms
</code></pre></li></ol><h2 id=configuring-vxlan-br0>Configuring VXLAN (br0)<a hidden class=anchor aria-hidden=true href=#configuring-vxlan-br0>#</a></h2><p>Now that we have the Wireguard tunnel up and running, next step is defining the VXLAN interface, plug it to a bridge interface and get the traffic encapsulated in the Wireguard tunnel.</p><p>In this example the VXLAN has a CIDR <code>172.16.30.0/24</code>.</p><h3 id=configuring-vxlan-in-hypervisor-1>Configuring VXLAN in Hypervisor 1<a hidden class=anchor aria-hidden=true href=#configuring-vxlan-in-hypervisor-1>#</a></h3><ul><li>Hypervisor 1 has its <code>wg0</code> interface configured with the <code>172.16.0.1</code> IP and can reach the Hypervisor 2 at <code>172.16.0.2</code> through the Wireguard tunnel.</li><li>Hypervisor 1 will configure <code>172.16.30.1/16</code> IP for <code>br0</code>. <code>to-node2</code> VXLAN interface will be configured with the <code>172.16.0.2</code> remote and plugged into the <code>br0</code> interface.</li></ul><p>Below commands rely on the <code>nmcli</code> tool, if your environment do not have it, you can refer to <a href=#alternative-commands-to-nmcli>alternative commands to nmcli section</a>.</p><ol><li><p>Create the bridge interface:</p><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>I&rsquo;m creating the bridge with spanning tree protocol disabled, you may want to enable it depending on your lab needs.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con add ifname br0 <span class=nb>type</span> bridge con-name br0 stp no ipv4.addresses 172.16.30.1/24 ipv4.method manual
</span></span></code></pre></div></li><li><p>Create the VXLAN interface:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con add ifname to-node2 <span class=nb>type</span> vxlan con-name to-node2 remote 172.16.0.2 id <span class=m>1</span> destination-port <span class=m>4789</span> ipv4.method disabled
</span></span></code></pre></div></li><li><p>Add the VXLAN interface to the bridge:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con modify to-node2 master br0
</span></span></code></pre></div></li><li><p>Bring up the bridge interface:</p><div class="admonition warning"><p class=admonition-title>Warning</p><p class=admonition>Be patient, the bridge may take a few seconds to be up.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con up br0
</span></span></code></pre></div></li></ol><h3 id=configuring-vxlan-in-hypervisor-2>Configuring VXLAN in Hypervisor 2<a hidden class=anchor aria-hidden=true href=#configuring-vxlan-in-hypervisor-2>#</a></h3><ul><li>Hypervisor 2 has its <code>wg0</code> interface configured with the <code>172.16.0.2</code> IP and can reach the Hypervisor 1 at <code>172.16.0.1</code> through the Wireguard tunnel.</li><li>Hypervisor 2 will configure <code>172.16.30.2/16</code> IP for <code>br0</code>. <code>to-node1</code> VXLAN interface will be configured with the <code>172.16.0.1</code> remote and plugged into the <code>br0</code> interface.</li></ul><ol><li><p>Create the bridge interface:</p><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>I&rsquo;m creating the bridge with spanning tree protocol disabled, you may want to enable it depending on your lab needs.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con add ifname br0 <span class=nb>type</span> bridge con-name br0 stp no ipv4.addresses 172.16.30.2/24 ipv4.method manual
</span></span></code></pre></div></li><li><p>Create the VXLAN interface:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con add ifname to-node1 <span class=nb>type</span> vxlan con-name to-node1 remote 172.16.0.1 id <span class=m>1</span> destination-port <span class=m>4789</span> ipv4.method disabled
</span></span></code></pre></div></li><li><p>Add the VXLAN interface to the bridge:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con modify to-node1 master br0
</span></span></code></pre></div></li><li><p>Bring up the bridge interface:</p><div class="admonition warning"><p class=admonition-title>Warning</p><p class=admonition>Be patient, the bridge may take a few seconds to be up.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con up br0
</span></span></code></pre></div></li></ol><h2 id=verifying-vxlan-configuration>Verifying VXLAN configuration<a hidden class=anchor aria-hidden=true href=#verifying-vxlan-configuration>#</a></h2><p>If everything went well, Hypervisors should be able to reach each other over the 172.16.30.0/24 network.</p><ol><li><p>Hypervisor 1 pings Hypervisor 2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ping -I br0 -c <span class=m>1</span> 172.16.30.2
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>PING 172.16.30.2 (172.16.30.2) from 172.16.30.1 br0: 56(84) bytes of data.
64 bytes from 172.16.30.2: icmp_seq=1 ttl=64 time=1.38 ms

--- 172.16.30.2 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.381/1.381/1.381/0.000 ms
</code></pre></li></ol><h2 id=configuring-vms-on-vxlan-network>Configuring VMs on VXLAN network<a hidden class=anchor aria-hidden=true href=#configuring-vms-on-vxlan-network>#</a></h2><p>For this part I&rsquo;ll be using the <a href=https://kcli.readthedocs.io/en/latest/>kcli</a> tool to interact with my KVM Hypervisors.</p><ol><li><p>If we check in our hypervisors we will have a new network available for our VMs, the <code>br0</code> network of type bridged:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kcli list networks
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>Listing Networks...
+-----------------+---------+---------------------+-------+-------------------+----------+
| Network         |   Type  |         Cidr        |  Dhcp |       Domain      |   Mode   |
+-----------------+---------+---------------------+-------+-------------------+----------+
| eth0            | bridged |     10.19.3.0/26    |  N/A  |        N/A        |   N/A    |
| br0             | bridged |    172.16.30.0/24   |  N/A  |        N/A        |   N/A    |
| default         |  routed |   192.168.122.0/24  |  True |      default      |   nat    |
+-----------------+---------+---------------------+-------+-------------------+----------+
</code></pre></li><li><p>I configured a DHCP server in the VXLAN network with DNSMasq, the relevant configuration can be found below:</p><div class="admonition attention"><p class=admonition-title>Attention</p><p class=admonition>I&rsquo;m running this DNSMasq in one of my hypervisors, node1 to be exact. Note that this node will act as router for the VXLAN network as well.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-ini data-lang=ini><span class=line><span class=cl><span class=na>dhcp-range</span><span class=o>=</span><span class=s>br0,172.16.30.50,172.16.30.200,255.255.255.0,24h</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-option</span><span class=o>=</span><span class=s>br0,option:dns-server,172.16.30.1</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-option</span><span class=o>=</span><span class=s>br0,option:ntp-server,172.16.30.1</span>
</span></span><span class=line><span class=cl><span class=na>dhcp-option</span><span class=o>=</span><span class=s>br0,option:router,172.16.30.1</span>
</span></span></code></pre></div></li><li><p>We can plug a new VM into this network, I&rsquo;ll run the command below in both hypervisors:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kcli download image centos9stream
</span></span><span class=line><span class=cl>kcli create vm -i centos9stream -P <span class=nv>nets</span><span class=o>=[</span>br0<span class=o>]</span> -P <span class=nv>name</span><span class=o>=</span>vm-hypervisorX
</span></span></code></pre></div></li><li><p>If I list the VMs in both hypervisors this is what I see:</p><ol><li><p>Hypervisor 1:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kcli list vm
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>+------------------+--------+---------------+
|       Name       | Status |       Ip      |
+------------------+--------+---------------+
|  vm-hypervisor1  |   up   |  172.16.30.59 |
+------------------+--------+---------------+
</code></pre></li><li><p>Hypervisor 2:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kcli list vm
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>+------------------+--------+----------------+
|       Name       | Status |       Ip       |
+------------------+--------+----------------+
|  vm-hypervisor2  |   up   |  172.16.30.143 |
+------------------+--------+----------------+
</code></pre></li></ol></li><li><p>As you can see both VMs got their IP via DHCP, we could have used static addressing as well. We can access one of the VMs and ping the other one.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kcli ssh vm-hypervisor1
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>[cloud-user@vm-hypervisor1 ~]$ ping -c1 172.16.30.143
PING 172.16.30.143 (172.16.30.143) 56(84) bytes of data.
64 bytes from 172.16.30.143: icmp_seq=1 ttl=64 time=1.94 ms

--- 172.16.30.143 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.935/1.935/1.935/0.000 ms
</code></pre></li><li><p>We were able to reach the other VM, if we try now to access internet or any other network not directly connected to our hypervisor node doing the routing this is what happens:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>[</span>cloud-user@vm-hypervisor1 ~<span class=o>]</span>$ ping -c1 1.1.1.1
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.
From 172.16.30.1 icmp_seq=1 Time to live exceeded

--- 1.1.1.1 ping statistics ---
1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms
</code></pre></li><li><p>If we want this VXLAN to access other networks we need to NAT the traffic, we can do that by running the following command in the hypervisor node doing the routing. Hypervisor 1 in my case:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo iptables -t nat -A POSTROUTING -s 172.16.30.0/24 -j MASQUERADE
</span></span></code></pre></div></li><li><p>If we try the ping again:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>[</span>cloud-user@vm-hypervisor1 ~<span class=o>]</span>$ ping -c1 1.1.1.1
</span></span></code></pre></div><pre tabindex=0><code class=language-output data-lang=output>PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.
64 bytes from 1.1.1.1: icmp_seq=1 ttl=41 time=27.2 ms

--- 1.1.1.1 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 27.175/27.175/27.175/0.000 ms
</code></pre></li></ol><h2 id=cleaning-up-the-environment>Cleaning up the environment<a hidden class=anchor aria-hidden=true href=#cleaning-up-the-environment>#</a></h2><p>In case we want to get rid of this setup we can run the following commands.</p><ol><li><p>Make sure all VMs using the VXLAN network are stopped and removed from the network.</p></li><li><p>In Hypervisor 1 run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con del br0
</span></span><span class=line><span class=cl>sudo nmcli con del to-node2
</span></span><span class=line><span class=cl>sudo systemctl stop wg-quick@wg0.service
</span></span><span class=line><span class=cl>sudo systemctl disable wg-quick@wg0.service
</span></span><span class=line><span class=cl>sudo iptables -t nat -D POSTROUTING -s 172.16.30.0/24 -j MASQUERADE
</span></span></code></pre></div></li><li><p>In Hypervisor 2 run:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo nmcli con del br0
</span></span><span class=line><span class=cl>sudo nmcli con del to-node1
</span></span><span class=line><span class=cl>sudo systemctl stop wg-quick@wg0.service
</span></span><span class=line><span class=cl>sudo systemctl disable wg-quick@wg0.service
</span></span></code></pre></div></li></ol><h2 id=alternative-commands-to-nmcli>Alternative commands to nmcli<a hidden class=anchor aria-hidden=true href=#alternative-commands-to-nmcli>#</a></h2><p>In case you don&rsquo;t have nmcli in your environment you can use the following IP commands instead:</p><ol><li><p>Hypervisor 1</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo ip link add name br0 <span class=nb>type</span> bridge stp_state <span class=m>0</span>
</span></span><span class=line><span class=cl>sudo ip address add dev br0 172.16.30.1/24
</span></span><span class=line><span class=cl>sudo ip link add to-node2 <span class=nb>type</span> vxlan remote 172.16.0.2 id <span class=m>1</span> dstport <span class=m>4789</span>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> up dev br0
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> up to-node2
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> to-node2 master br0
</span></span></code></pre></div></li><li><p>Hypervisor 2</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo ip link add name br0 <span class=nb>type</span> bridge stp_state <span class=m>0</span>
</span></span><span class=line><span class=cl>sudo ip address add dev br0 172.16.30.2/24
</span></span><span class=line><span class=cl>sudo ip link add to-node1 <span class=nb>type</span> vxlan remote 172.16.0.1 id <span class=m>1</span> dstport <span class=m>4789</span>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> up dev br0
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> up to-node1
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> to-node1 master br0
</span></span></code></pre></div></li><li><p>Cleanup</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sudo ip link del br0
</span></span><span class=line><span class=cl>sudo ip link del to-node1
</span></span><span class=line><span class=cl>sudo ip link del to-node2
</span></span></code></pre></div></li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>In order to achieve the work described here I used several resources from different places. I want to thank these wonderful people that created such awesome content I could make this work.</p><ul><li><a href=https://gist.github.com/pamolloy/f464c2b54af03c436491f42abf0bbff9>https://gist.github.com/pamolloy/f464c2b54af03c436491f42abf0bbff9</a></li><li><a href=https://jrcichra.dev/posts/transparent-wireguard-networks-in-kvm/>https://jrcichra.dev/posts/transparent-wireguard-networks-in-kvm/</a></li><li><a href=https://www.tallwireless.com/posts/2020/03/21/tunnels-tunnels-tunnels/>https://www.tallwireless.com/posts/2020/03/21/tunnels-tunnels-tunnels/</a></li><li><a href=https://rob-turner.net/post/vx-lan/>https://rob-turner.net/post/vx-lan/</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://linuxera.org/tags/wireguard/>wireguard</a></li><li><a href=https://linuxera.org/tags/networking/>networking</a></li><li><a href=https://linuxera.org/tags/vxlan/>vxlan</a></li></ul><nav class=paginav><a class=prev href=https://linuxera.org/signing-verifying-container-images-with-cosign-own-pki/><span class=title>¬´ Prev</span><br><span>Signing and verifying container images with Cosign and your own PKI</span></a>
<a class=next href=https://linuxera.org/running-vault-on-podman/><span class=title>Next ¬ª</span><br><span>Running Vault on Podman</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Extending a VXLAN across nodes with Wireguard on twitter" href="https://twitter.com/intent/tweet/?text=Extending%20a%20VXLAN%20across%20nodes%20with%20Wireguard&url=https%3a%2f%2flinuxera.org%2fextending-vxlan-across-nodes-with-wireguard%2f&hashtags=wireguard%2cnetworking%2cvxlan"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Extending a VXLAN across nodes with Wireguard on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2flinuxera.org%2fextending-vxlan-across-nodes-with-wireguard%2f&title=Extending%20a%20VXLAN%20across%20nodes%20with%20Wireguard&summary=Extending%20a%20VXLAN%20across%20nodes%20with%20Wireguard&source=https%3a%2f%2flinuxera.org%2fextending-vxlan-across-nodes-with-wireguard%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></div></footer><div class=share-buttons><p>If this post has been helpful to you, consider <u><a target=_blank href=https://ko-fi.com/mvazce>supporting the work.</a></u></p></div><script src=https://utteranc.es/client.js repo=mvazquezc/mvazquezc.github.io issue-term=pathname label=blog-comments theme=preferred-color-scheme crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://linuxera.org/>Linuxera</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>