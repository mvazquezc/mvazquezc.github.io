<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Linuxera</title>
    <link>https://linuxera.org/posts/</link>
    <description>Recent content in Posts on Linuxera</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://linuxera.org/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Beginner’s Guide to RAG: What I Wish Someone Told Me</title>
      <link>https://linuxera.org/rag-beginners-guide/</link>
      <pubDate>Tue, 27 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/rag-beginners-guide/</guid>
      <description>A Beginner’s Guide to RAG: What I Wish Someone Told Me In this post, I&amp;rsquo;ll try to provide a beginners guide to RAG, focusing on what I wish someone told me before trying to build a RAG solution.
Attention
While I’ve made a strong effort to ensure the information is accurate, I’m far from an expert on the topic, and some details may not be entirely correct. If you notice anything missing or inaccurate, please leave a comment!</description>
    </item>
    
    <item>
      <title>Introduction to LLM concepts</title>
      <link>https://linuxera.org/introduction-to-llm-concepts/</link>
      <pubDate>Tue, 25 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/introduction-to-llm-concepts/</guid>
      <description>Introduction to LLM concepts In this post, I&amp;rsquo;ll cover various LLM concepts and the questions I asked myself while diving deep into the world of LLMs. I expect this post to be updated as I continue to learn more things around LLMs.
Attention
This post is the result of my exploratory work on LLMs. While I’ve made a strong effort to ensure the information is accurate, I’m far from an expert on the topic, and some details may not be entirely correct.</description>
    </item>
    
    <item>
      <title>Signing and verifying container images with Cosign and your own PKI</title>
      <link>https://linuxera.org/signing-verifying-container-images-with-cosign-own-pki/</link>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/signing-verifying-container-images-with-cosign-own-pki/</guid>
      <description>Signing and verifying container images with Cosign and your own PKI In this post we are going to cover how we can sign and verify container images using Cosign and our own PKI. You can learn more on how to build your own PKI with CFSSL in this post.
Warning
The way we will see to sign and verify images in this post is not the recommended approach. For production usage, you should use ephemeral keys as described here.</description>
    </item>
    
    <item>
      <title>Extending a VXLAN across nodes with Wireguard</title>
      <link>https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/extending-vxlan-across-nodes-with-wireguard/</guid>
      <description>Extending a VXLAN across nodes with Wireguard Virtualizing environments is something I do quite often in a day-to-day basis, usually, these environments live in different hypervisors. While I don&amp;rsquo;t always need these environments to talk to each other, from time to time I need some sort of connectivity between them.
Getting the VMs running on these hypervisors routed through the lab network is one of the solutions I have been using for a long time.</description>
    </item>
    
    <item>
      <title>Running Vault on Podman</title>
      <link>https://linuxera.org/running-vault-on-podman/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/running-vault-on-podman/</guid>
      <description>Running Vault on Podman This post explains how to run a local Vault deployment on Podman for non-production use. I typically use this setup for my lab environments.
This setup was tested with:
Podman v4.7.2 Podman-compose v1.0.6 Vault v1.15.2 Prerequisites Install the vault client, you can get the binary for your O.S here.
curl -L https://releases.hashicorp.com/vault/1.15.2/vault_1.15.2_linux_amd64.zip -o /tmp/vault.zip unzip /tmp/vault.zip &amp;amp;&amp;amp; rm -f /tmp/vault.zip sudo mv vault /usr/local/bin/ Generate folder for storing the configs, data, and certs.</description>
    </item>
    
    <item>
      <title>Integrating cert-manager with CFSSL Multirootca</title>
      <link>https://linuxera.org/integrating-cert-manager-with-cfssl-multirootca/</link>
      <pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/integrating-cert-manager-with-cfssl-multirootca/</guid>
      <description>Integrating cert-manager with CFSSL Multirootca In a previous post we saw how we could run our own PKI using the CFSSL tooling. This post assumes you have read the previous one.
The starting point is an empty Kubernetes cluster, we want to deploy cert-manager on it and on top of that we want to get it configured to issue certificates with our own PKI infrastructure running Multirootca.
I’ll be using a Kubernetes v1.</description>
    </item>
    
    <item>
      <title>PKI with CFSSL</title>
      <link>https://linuxera.org/pki-with-cfssl/</link>
      <pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/pki-with-cfssl/</guid>
      <description>PKI with CFSSL In this post we will learn how to deploy our own Public Key Infrastructure (PKI) by using the CFSSL tooling. This may be useful if you want to run your own Certificate Authority (CA) in order to issue certificates for your systems and/or users.
Introduction to CFSSL CFSSL is a tool set created by Cloudflare and released as Open Source software. Before you continue reading this post I&amp;rsquo;d suggest reading this introductory post to PKI and CFSSL by Cloudflare.</description>
    </item>
    
    <item>
      <title>Gateway API for Kubernetes</title>
      <link>https://linuxera.org/gateway-api-kubernetes/</link>
      <pubDate>Mon, 24 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/gateway-api-kubernetes/</guid>
      <description>Gateway API for Kubernetes In this post we will go over a new project by the SIG-NETWORK that aims to evolve Kubernetes service networking.
I&amp;rsquo;ll be using a Kubernetes v1.26 (latest at the time of this writing). The tool used to create the cluster is kcli and the command used was:
kcli create kube generic -P ctlplanes=1 -P workers=1 -P ctlplane_memory=4096 -P numcpus=8 -P worker_memory=8192 -P image=fedora37 -P sdn=calico -P version=1.</description>
    </item>
    
    <item>
      <title>CPU and Memory Management on Kubernetes with Cgroupsv2</title>
      <link>https://linuxera.org/cpu-memory-management-kubernetes-cgroupsv2/</link>
      <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/cpu-memory-management-kubernetes-cgroupsv2/</guid>
      <description>CPU and Memory Management on Kubernetes with Cgroupsv2 In this post I&amp;rsquo;ll try to explain how CPU and Memory management works under the hood on Kubernetes. If you ever wondered what happens when you set requests and limits for your pods, keep reading!
Attention
This is the result of my exploratory work around cgroupsv2 and their application to Kubernetes. Even though I tried really hard to make sure the information in this post is accurate, I&amp;rsquo;m far from being an expert on the topic and some information may not be 100% accurate.</description>
    </item>
    
    <item>
      <title>Exposing multiple Kubernetes clusters with a single load balancer and a single public IP</title>
      <link>https://linuxera.org/exposing-multiple-kubernetes-clusters-single-lb-and-ip/</link>
      <pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/exposing-multiple-kubernetes-clusters-single-lb-and-ip/</guid>
      <description>Exposing multiple Kubernetes clusters with a single load balancer and a single public IP My colleague Alberto Losada and I have been working on a lab lately. The lab is composed of three OpenShift clusters on VMs, these VMs are deployed on an isolated libvirt network, which means that we cannot access them from outside the hypervisor.
In order to solve this issue, we wanted to expose the three clusters using the public IP available in the hypervisor.</description>
    </item>
    
    <item>
      <title>Enhanced Version and Build Information for your Go programs with ldflags</title>
      <link>https://linuxera.org/enhanced-version-and-build-information-for-your-go-programs/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/enhanced-version-and-build-information-for-your-go-programs/</guid>
      <description>Enhanced Version and Build Information for your Go programs with ldflags In the previous post we show how to create a simple CLI in Go with Cobra. I received a suggestion from one of my colleagues, Andrew Block. He suggested complementing that post with the use of ldflags at build time in order to define specific information to a specific build like build time, git commit, etc.
Andy is also running a blog, go check it out!</description>
    </item>
    
    <item>
      <title>Writing CLIs in Go with Cobra</title>
      <link>https://linuxera.org/writing-clis-go-cobra/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/writing-clis-go-cobra/</guid>
      <description>Writing CLIs in Go using Cobra A few months ago, I was working with my colleague Alberto in a CLI. The language of choice was Go and I manage to learn a thing or two. In today&amp;rsquo;s post we will see a very basic skeleton for a CLI written in Go. This will certainly help me in the future as a template for the next CLI, and maybe it helps you too!</description>
    </item>
    
    <item>
      <title>OpenShift 4 User Certificates</title>
      <link>https://linuxera.org/user-certificates-in-openshift4/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/user-certificates-in-openshift4/</guid>
      <description>User Certificates in OpenShift 4 Attention
The information described in this blog post may not be a supported configuration for OpenShift 4. Please, refer to the official docs for supported documentation.
In this blog we will see how we can create OpenShift Users using client certificates and how to configure the API Server, so we can create client certificates using custom CAs. The information described in this blog was last tested with OpenShift 4.</description>
    </item>
    
    <item>
      <title>Working with Pod Security Standards</title>
      <link>https://linuxera.org/working-with-pod-security-standards/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/working-with-pod-security-standards/</guid>
      <description>Working with Pod Security Standards In Kubernetes v1.25 Pod Security admission has moved to stable, replacing Pod Security Policy admission. This feature has been in beta and enabled by default since Kubernetes v1.23 in this post we are going to cover what&amp;rsquo;s new with Pod Security Admission (PSA) and how it affects the workloads being deployed in our clusters.
Note
For this post I&amp;rsquo;ll be running a Kubernetes v1.25 cluster. If you want to try this in your own environment you can use your favorite tool to get a K8s cluster up and running, I&amp;rsquo;ll be using kcli.</description>
    </item>
    
    <item>
      <title>Capabilities and Seccomp Profiles on Kubernetes</title>
      <link>https://linuxera.org/capabilities-seccomp-kubernetes/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/capabilities-seccomp-kubernetes/</guid>
      <description>Capabilities and Seccomp Profiles on Kubernetes In a previous post we talked about Linux Capabilities and Secure Compute Profiles, in this post we are going to see how we can leverage them on Kubernetes.
We will need a Kubernetes cluster, I&amp;rsquo;m going to use kcli in order to get one. Below command will deploy a Kubernetes cluster on VMs:
NOTE: You can create a parameters file with the cluster configuration as well.</description>
    </item>
    
    <item>
      <title>Container Security - Linux Capabilities and Secure Compute Profiles</title>
      <link>https://linuxera.org/container-security-capabilities-seccomp/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/container-security-capabilities-seccomp/</guid>
      <description>Container Security - Linux Capabilities and Secure Compute Profiles In this post we are going to see two security mechanisms used in Linux Containers in order to provide a security layer for our workloads.
We will see how Linux Capabilities and Secure Compute Profiles can be used for limiting the attack surface for our containers.
The first part of the blog post will be an introduction to Linux Capabilities and Secure Compute Profiles, second part will show how these technologies work through the use of demos.</description>
    </item>
    
    <item>
      <title>Containers under the Hood</title>
      <link>https://linuxera.org/containers-under-the-hood/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/containers-under-the-hood/</guid>
      <description>Containers are Linux You probably already heard this expression, in today&amp;rsquo;s post we are going to desmitify container technologies by decomposing them part by part and describing which Linux technologies make containers possible.
We can describe a container as an isolated process running on a host. In order to isolate the process the container runtimes leverage Linux kernel technologies such as: namespaces, chroots, cgroups, etc. plus security layers like SELinux.</description>
    </item>
    
    <item>
      <title>Integrating our Operators with OLM</title>
      <link>https://linuxera.org/integrating-operators-olm/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/integrating-operators-olm/</guid>
      <description>Introduction This post is a continuation of our previous blog Writing Operators using the Operator Framework SDK.
We will continue working on the operator created on the previous blog, if you want to be able to follow this blog, you will need to run the steps from the previous blog.
Operator Lifecycle Manager The Operator Lifecycle Manager is an open source toolkit to manage Operators in an effective, automated and scalable way.</description>
    </item>
    
    <item>
      <title>Enabling Prometheus Metrics on your Applications</title>
      <link>https://linuxera.org/prometheus-metrics-on-your-applications/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/prometheus-metrics-on-your-applications/</guid>
      <description>Instrumenting your Applications We usually see systems being monitored by Ops teams, in fact, there are lots of valuable metrics that help Ops teams understand how the infrastructure they are managing is doing, but when it comes to applications monitoring, we don&amp;rsquo;t see those being monitored that carefully most of the time. Sometimes that ends up in application crashes that might be prevented with a proper monitoring strategy.
In this blog post we are going to see how we can instrument our applications using Prometheus metrics libraries.</description>
    </item>
    
    <item>
      <title>Using OpenShift OAuth Proxy to secure your Applications on OpenShift</title>
      <link>https://linuxera.org/oauth-proxy-secure-applications-openshift/</link>
      <pubDate>Tue, 30 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/oauth-proxy-secure-applications-openshift/</guid>
      <description>What is OAuth Proxy A reverse proxy and static file server that provides authentication and authorization to an OpenShift OAuth server or Kubernetes master supporting the 1.6+ remote authorization endpoints to validate access to content. It is intended for use withing OpenShift clusters to make it easy to run both end-user and infrastructure services that do not provider their own authentication.
[Source]
Securing an Application with OAuth Proxy In this blog post we are going to deploy OAuth Proxy in front of a simple application.</description>
    </item>
    
    <item>
      <title>Writing Operators using the Operator Framework SDK</title>
      <link>https://linuxera.org/writing-operators-using-operator-framework/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://linuxera.org/writing-operators-using-operator-framework/</guid>
      <description>Operators, operators everywhere As you may have noticed, Kubernetes operators are becoming more an more popular those days. In this post we are going to explain the basics around Operators and we will develop a simple Operator using the Operator Framework SDK.
What is an Operator An operator aims to automate actions usually performed manually while lessening the likelihood of error and simplifying complexity.
We can think of an operator as a method of packaging, deploying and managing a Kubernetes enabled application.</description>
    </item>
    
  </channel>
</rss>
